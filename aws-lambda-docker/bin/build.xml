<?xml version="1.0" encoding="UTF-8"?>
<project name="TranformXml" default="full"
    xmlns:if="ant:if"
    xmlns:unless="ant:unless">
    <dirname property="buildfile.dir" file="${ant.file}"/>

    <property environment="env"/>
    <!-- The following switches can be passed when invoking ant to provide custom values -->
    <property name="data.dir"  value="../cudl-data-source"/><!-- Source of the original data files -->
    <property name="collection.json.dir"  value="${data.dir}/collections"/><!-- Source of the collection json files -->
    <property name="dist-pending.dir"  value="../dist-pending"/><!-- Initial output directory -->
    <property name="dist.dir"  value="../dist"/><!-- Final dist dir (local build only) -->
    <property name="files-to-process" value="*.xml"/><!-- File(s) to build -->
    <property name="ENVIRONMENT" value="${env.ENVIRONMENT}"/>

    <!-- Internal directories used during the build process -->
    <property name="chunk.dir"  value="../chunk"/><!-- Chunk directory: target of the chunking process; source of data for the pagify process -->
    <property name="tmp.dir"  value="../tmp"/><!-- Target directory for the TEI XML page extract files -->
    <property name="dev.null"  value="../dev.null"/><!-- Destination directory for empty junk files created by ant's xslt task when running pagify.xsl -->

    <!-- Initial output subdirectories within $dist-pending.dir -->
    <property name="www.pending.dir"  value="${dist-pending.dir}/www"/><!-- Target directory for www resources -->

    <!-- Target directory for TEI XML page files -->
    <property unless:blank="${env.PAGE_XML_SOURCE}" name="page-xml.pending.dir" value="${env.PAGE_XML_SOURCE}"/>
    <property if:blank="${env.PAGE_XML_SOURCE}" name="page-xml.pending.dir" value="${dist-pending.dir}/page-xml"/>

    <property name="tei_full.pending.dest"  value="${dist-pending.dir}"/><!-- target directory for original TEI file (along with its path hierarchy) -->
    <property name="tei_full.pending.src"  value="${dist-pending.dir}/items"/><!-- source directory for the original TEI file copied to the pending dist dir -->
    <property name="default.core_xml.pending.dir"  value="${dist-pending.dir}/core-xml"/><!-- target of the xtf indexing results. Source for json xslt -->

    <property name="viewer-json.pending.dir"  value="${dist-pending.dir}/json-viewer"/><!-- Destination dir for json viewer -->
    <property name="solr-json.pending.dir"  value="${dist-pending.dir}/json-solr"/><!-- Destination dir for json solr -->
    <property name="dp-json.pending.dir"  value="${dist-pending.dir}/json-dp"/><!-- Destination dir for json digital preservation -->

    <property name="checksum-src.dir"  value="${dist-pending.dir}/checksum-src"/>

    <!-- Final S3 Destinations -->
    <property name="AWS_DIST_BUCKET" value="${env.AWS_DIST_BUCKET}"/>
    <property name="core_xml-s3-dest" value="${AWS_DIST_BUCKET}/core-xml"/>
    <property name="www-s3-dest" value="${AWS_DIST_BUCKET}/html"/>
    <property name="page-xml-s3-dest" value="${AWS_DIST_BUCKET}/page-xml"/>
    <property name="tei-full-s3-dest" value="${AWS_DIST_BUCKET}/items"/>
    <property name="dp-json-s3-dest" value="${AWS_DIST_BUCKET}/dp-json"/>
    <property name="solr-json-s3-dest" value="${AWS_DIST_BUCKET}/solr-json"/>
    <property name="viewer-json-s3-dest" value="${AWS_DIST_BUCKET}/viewer-json"/>

    <condition property="SEARCH_HOST" value="${env.SEARCH_HOST}" else="">
        <isset property="env.SEARCH_HOST" />
    </condition>

    <condition property="SEARCH_PORT" value="${env.SEARCH_PORT}" else="">
        <isset property="env.SEARCH_PORT" />
    </condition>

    <condition property="SEARCH_COLLECTION_PATH" value="${env.SEARCH_COLLECTION_PATH}" else="">
        <isset property="env.SEARCH_COLLECTION_PATH" />
    </condition>

    <property name="collection_xml.dir" value="${AWS_DIST_BUCKET}/collection-xml"/><!-- collection info broken down by file -->

    <condition property="no.copy.xml" value="true" else="false">
        <contains string="json,solr,dp,viewer" substring="${env.ANT_TARGET}"/>
    </condition>

    <condition property="no.copy.page-xml" value="true" else="false">
        <equals arg1="${env.ANT_TARGET}" arg2="html" />
    </condition>

    <target name="if.core.source.overide">
        <property unless:blank="${env.CORE_XML_SOURCE}" name="core_xml.pending.dir" value="${env.CORE_XML_SOURCE}"/>
        <property if:blank="${env.CORE_XML_SOURCE}" name="core_xml.pending.dir" value="${dist-pending.dir}/core-xml"/>
    </target>

    <!-- Comprehensive builds -->

    <target name="full" depends="if.core.source.overide, metadata-and-transcripts, _json">
        <antcall target="release-outputs"/>
    </target>

    <target name="full-metadata-update" depends="if.core.source.overide, metadata, _json">
        <antcall target="release-outputs"/>
    </target>

    <target name="metadata-and-transcripts" depends="transcripts, metadata"/>


    <target name="transcripts" depends="_create-pages, _transform-pages">

        <retry retrycount="6">
            <delete dir="${chunk.dir}" failonerror="no" />
        </retry>
        <retry retrycount="6">
            <delete dir="${tmp.dir}" failonerror="no" />
        </retry>
        <retry retrycount="6">
            <delete dir="${dev.null}" />
        </retry>
    </target>

    <target name="_copy_tei_full_to_dist_pending">
        <copy todir="${tei_full.pending.dest}">
            <fileset dir="${data.dir}" includes="${files-to-process}" />
        </copy>
    </target>

    <target name="metadata">
        <mkdir dir="${core_xml.pending.dir}"/>

        <antcall target="_copy_tei_full_to_dist_pending"/>

        <fileset id="original_xml" dir="${data.dir}" includes="${files-to-process}" />

        <xslt destdir="${core_xml.pending.dir}" style="../xslt/msTeiPreFilter.xsl" force="true" useimplicitfileset="false" extension=".xml" reloadstylesheet="true">
            <fileset refid="original_xml"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
            <param name="path_to_buildfile" expression="${buildfile.dir}"/>
            <param name="dest_dir" expression="${www.pending.dir}"/>
            <param name="data_dir" expression="${data.dir}"/>
            <param name="collection_xml_dir" expression="${collection_xml.dir}"/>
            <param name="SEARCH_HOST" expression="${SEARCH_HOST}"/>
            <param name="SEARCH_PORT" expression="${SEARCH_PORT}"/>
            <param name="SEARCH_COLLECTION_PATH" expression="${SEARCH_COLLECTION_PATH}"/>
        </xslt>
    </target>

    <target name="_json" depends="_viewer-json, _solr-json, _dp-json"/>

    <target name="solr" depends="_solr-json, release-outputs"/>
    <target name="viewer" depends="_viewer-json, release-outputs"/>
    <target name="dp" depends="_dp-json, release-outputs"/>
    <target name="json" depends="_json, release-outputs"/>
    <target name="html" depends="_html, if.core.source.overide, metadata, _json, release-outputs"/>

    <target name="_viewer-json" depends="if.core.source.overide">
        <echo message="Generating viewer json files"/>

        <property name="json-tmp.dir"  value="../json-tmp"/>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>

        <mkdir dir="${json-tmp.dir}"/>
        <mkdir dir="${viewer-json.pending.dir}"/>

        <fileset id="indexed_files" dir="${core_xml.pending.dir}" includes="${files-to-process}" />

        <xslt destdir="${json-tmp.dir}" style="../xslt/viewer-json.xsl" force="true" useimplicitfileset="false" extension=".json" reloadstylesheet="true">
            <fileset refid="indexed_files"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
        </xslt>

        <move todir="${viewer-json.pending.dir}" flatten="true">
            <fileset dir="${json-tmp.dir}">
                <include name="**/*.json"/>
            </fileset>
        </move>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>
    </target>

    <target name="_dp-json" depends="if.core.source.overide">
        <echo message="Generating DP json file"/>

        <property name="json-tmp.dir"  value="../json-tmp"/>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>

        <mkdir dir="${json-tmp.dir}"/>
        <mkdir dir="${dp-json.pending.dir}"/>

        <fileset id="indexed_files" dir="${core_xml.pending.dir}" includes="${files-to-process}" />

        <xslt destdir="${json-tmp.dir}" style="../xslt/dp-json.xsl" force="true" useimplicitfileset="false" extension=".json" reloadstylesheet="true">
            <fileset refid="indexed_files"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
        </xslt>

        <move todir="${dp-json.pending.dir}" flatten="true">
            <fileset dir="${json-tmp.dir}">
                <include name="**/*.json"/>
            </fileset>
        </move>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>
    </target>

    <target name="_solr-json" depends="if.core.source.overide">
        <echo message="Generating solr json files"/>

        <property name="json-tmp.dir"  value="../json-tmp"/>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>

        <mkdir dir="${json-tmp.dir}"/>
        <mkdir dir="${solr-json.pending.dir}"/>

        <fileset id="indexed_files" dir="${core_xml.pending.dir}" includes="${files-to-process}" />

        <xslt destdir="${json-tmp.dir}" style="../xslt/solr-json.xsl" force="true" useimplicitfileset="false" extension=".json" reloadstylesheet="true">
            <fileset refid="indexed_files"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
        </xslt>

        <move todir="${solr-json.pending.dir}" flatten="true">
            <fileset dir="${json-tmp.dir}">
                <include name="**/*.json"/>
            </fileset>
        </move>

        <retry retrycount="6">
            <delete dir="${json-tmp.dir}" failonerror="no" />
        </retry>
    </target>

    <!-- Private tasks called from main tasks -->

    <target name="_create-pages">
        <retry retrycount="6">
            <delete dir="${chunk.dir}" failonerror="no" />
        </retry>

        <!-- Do we remove any unused transcription pages or leave them?
            Since the major work occurs on staging, it might be possible to
            create a lambda that does a preflight tidy of all resources. It
            would require processor power to work, but the existing test build
            would provide a basis for identifying pages not pointed to by core-xml.
            Removed classmarks would require collecting all the base file globs
            (non-transc stuff) and comparing with what's in the data source.
            The collections could be rebuilt after this for one final check, if
            needed
        -->
        <!--<retry retrycount="6">
            <delete dir="${web.dir}" />
            </retry>-->
        <retry retrycount="6">
            <delete dir="${dev.null}" />
        </retry>

        <mkdir dir="${chunk.dir}"/>
        <mkdir dir="${www.pending.dir}"/>

        <fileset id="original_xml" dir="${data.dir}" includes="${files-to-process}" />

        <echo>Breaking files into smaller chunks</echo>
        <!-- pagify.xsl creates multiple output files from each document passed to it using xsl:result-document. It replicates the hierarchy of the
            data files using the path_to_buildfile, data_dir parameters and creates the same hierarchy in dest_dir.

            Unfortunately, ant's xslt task  can't tell (or be made to realise) that an xsl stylesheet might be manually outputting files using
            xsl:result-document. It assumes that each document passed to it will produce a single result document written to <xslt>/@destdir.
            This isn't a problem for the render phase of the process (msTeiTrans.xsl) since that's precisely what we want. However, for this
            transformation, we end up with:
            a) the actual xsl:result-document that are written to dest_dir
            b) a series of empty .html documents written to <xslt>/@destdir. Normally, I'd have made @destdir point to /dev/null, but this
            causes errors because ant tries to replicate the folder hierarchy there and this causes an error. I therefore have forced these
            files to be written to dev.null (defined above).

            None of this is new. It's how the transformation has always run. It's just that I felt the need to document it better now.
        -->
        <xslt destdir="${dev.null}" style="../xslt/transcription/pagify.xsl" force="true" useimplicitfileset="false" reloadstylesheet="true">
            <fileset refid="original_xml"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
            <param name="path_to_buildfile" expression="${buildfile.dir}"/>
            <param name="dest_dir" expression="${chunk.dir}"/>
            <param name="data_dir" expression="${data.dir}"/>
            <param name="num_chunks" expression="8"/>
        </xslt>

        <retry retrycount="6">
            <delete dir="${dev.null}" />
        </retry>
    </target>

    <target name="_transform-pages" if="${files.exist}" depends="if.chunks.exist">
        <echo>Paginating XML</echo>

        <fileset id="chunk_xml" dir="${chunk.dir}" includes="**/*.xml" />

        <xslt destdir="${dev.null}" style="../xslt/transcription/pagify.xsl" force="true" useimplicitfileset="false" reloadstylesheet="true">
            <fileset refid="chunk_xml"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
            <param name="path_to_buildfile" expression="${buildfile.dir}"/>
            <param name="dest_dir" expression="${page-xml.pending.dir}"/>
            <param name="data_dir" expression="${chunk.dir}"/>
            <param name="num_chunks" expression="1"/>
        </xslt>

        <retry retrycount="6">
            <delete dir="${dev.null}" />
        </retry>

        <antcall target="_html"/>

    </target>

    <target name="_html">
        <echo>Transforming page xml into html</echo>

        <loadresource property="page_xml_items.dir">
            <propertyresource name="files-to-process"/>
            <filterchain>
                <tokenfilter>
                    <replaceregex pattern="/[^/]+$" replace="" flags="g"/>
                </tokenfilter>
            </filterchain>
        </loadresource>

        <fileset id="page_files" dir="${page-xml.pending.dir}" includes="${page_xml_items.dir}/*.xml" />

        <xslt destdir="${www.pending.dir}" style="../xslt/transcription/msTeiTrans.xsl" force="true" useimplicitfileset="false" extension=".html" reloadstylesheet="true">
            <fileset refid="page_files"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
        </xslt>

        <antcall target="_copy_web_resources"/>

        <retry retrycount="6">
            <delete dir="${chunk.dir}" failonerror="no" />
        </retry>
    </target>

    <target name="_copy_web_resources" depends="if.local.environment">

        <copy if:true="${is.local.environment}" todir="${www.pending.dir}">
            <fileset dir="../xslt/transcription/web/">
            </fileset>
        </copy>
    </target>

    <target name="collection-update" depends="_update-core-xml, _viewer-json, _solr-json"/>

    <target name="_update-core-xml">
        <echo message="Updating core-xml collection info"/>

        <property name="dest_tmp.dir" value="${core_xml.pending.dir}-tmp"/>

        <retry retrycount="6">
            <delete dir="${dest_tmp.dir}" failonerror="no" />
        </retry>

        <mkdir dir="${dest_tmp.dir}"/>

        <fileset id="core_xml" dir="${core_xml.pending.dir}" includes="${files-to-process}" />

        <xslt destdir="${dest_tmp.dir}" style="../xslt/update-collection-info.xsl" force="true" useimplicitfileset="false" extension=".xml" reloadstylesheet="true">
            <fileset refid="core_xml"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
            <param name="path_to_buildfile" expression="${buildfile.dir}"/>
            <param name="collection_xml_dir" expression="${collection_xml.dir}"/>
        </xslt>

        <copy todir="${core_xml.pending.dir}" >
            <fileset dir="${dest_tmp.dir}">
                <include name="**/*.xml"/>
            </fileset>
        </copy>
    </target>

    <target name="checksum-sources">
        <echo>Writing checksum sources</echo>

        <retry retrycount="6">
            <delete dir="${checksum-src.dir}" failonerror="no" />
        </retry>

        <mkdir dir="${checksum-src.dir}"/>

        <fileset id="original_xml" dir="${data.dir}" includes="${files-to-process}" />

        <xslt destdir="${dev.null}" style="../xslt/transcription/checksum-source.xsl" force="true" useimplicitfileset="false" reloadstylesheet="true">
            <fileset refid="original_xml"/>
            <factory name="net.sf.saxon.TransformerFactoryImpl">
                <attribute name="http://saxon.sf.net/feature/xinclude-aware"
                    value="true"/>
            </factory>
            <param name="path_to_buildfile" expression="${buildfile.dir}"/>
            <param name="data_dir" expression="${data.dir}"/>
            <param name="dest_dir" expression="${checksum-src.dir}"/>
        </xslt>
    </target>


    <target name="release-outputs" depends="if.local.environment">

        <antcall if:true="${is.local.environment}" target="_copy_to_dist"/>
        <antcall unless:true="${is.local.environment}" target="_copy_to_s3"/>

    </target>

    <target name="_copy_to_dist">
        <copy todir="${dist.dir}">
            <fileset dir="${dist-pending.dir}">
                <include name="**/*"/>
            </fileset>
        </copy>

    </target>

    <target name="_copy_to_s3">
        <parallel>
            <antcall target="_copy_tei_full_to_s3"/>
            <antcall unless:true="${no.copy.xml}" target="_copy_xml_derivs_to_s3"/>
            <antcall target="_copy_www_to_s3"/>
            <antcall target="_copy_viewer_json_to_s3"/>
            <antcall target="_copy_dp_json_to_s3"/>
            <antcall target="_copy_solr_json_to_s3"/>
        </parallel>
    </target>

    <target name="_copy_tei_full_to_s3">
        <echo message="Copying ${tei_full.pending.src} to S3://${tei-full-s3-dest}"/>
        <exec executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${tei_full.pending.src}"/>
            <arg value="s3://${tei-full-s3-dest}"/>
        </exec>
    </target>

    <target name="_copy_xml_derivs_to_s3">
        <echo message="Copying ${core_xml.pending.dir} to S3://${core_xml-s3-dest}"/>
        <exec executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${core_xml.pending.dir}"/>
            <arg value="s3://${core_xml-s3-dest}"/>
        </exec>

        <echo unless:true="${no.copy.page-xml}" message="Copying ${page-xml.pending.dir} to S3://${page-xml-s3-dest}"/>
        <exec unless:true="${no.copy.page-xml}" executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${page-xml.pending.dir}"/>
            <arg value="s3://${page-xml-s3-dest}"/>
        </exec>

    </target>

    <target name="_copy_www_to_s3">

        <condition property="www.exists" value="true" else="false"><available file="${www.pending.dir}/items" type="dir"/></condition>
        <echo if:true="${www.exists}" message="Copying ${www.pending.dir}/items/ to S3://${www-s3-dest}"/>
        <exec if:true="${www.exists}" executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${www.pending.dir}/items/"/>
            <arg value="s3://${www-s3-dest}"/>
        </exec>
    </target>

    <target name="_copy_viewer_json_to_s3">

        <condition property="viewer-json.exists" value="true" else="false"><available file="${viewer-json.pending.dir}" type="dir"/></condition>
        <echo if:true="${viewer-json.exists}" message="Copying ${viewer-json.pending.dir} to S3://${viewer-json-s3-dest}"/>
        <exec if:true="${viewer-json.exists}" executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${viewer-json.pending.dir}"/>
            <arg value="s3://${viewer-json-s3-dest}"/>
        </exec>
    </target>

    <target name="_copy_dp_json_to_s3">
        <condition property="dp-json.exists" value="true" else="false"><available file="${dp-json.pending.dir}" type="dir"/></condition>
        <echo if:true="${dp-json.exists}" message="Copying ${dp-json.pending.dir} to S3://${dp-json-s3-dest}"/>
        <exec if:true="${dp-json.exists}" executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${dp-json.pending.dir}"/>
            <arg value="s3://${dp-json-s3-dest}"/>
        </exec>
    </target>

    <target name="_copy_solr_json_to_s3">
        <condition property="solr-json.exists" value="true" else="false"><available file="${solr-json.pending.dir}" type="dir"/></condition>
        <echo if:true="${solr-json.exists}" message="Copying ${solr-json.pending.dir} to S3://${solr-json-s3-dest}"/>
        <exec if:true="${solr-json.exists}" executable="aws" resolveexecutable="true">
            <arg value="s3"/>
            <arg value="sync"/>
            <arg value="--quiet"/>
            <arg value="${solr-json.pending.dir}"/>
            <arg value="s3://${solr-json-s3-dest}"/>
        </exec>
    </target>

    <target name="if.local.environment">
        <condition property="is.local.environment" value="true" else="false">
            <equals arg1="${ENVIRONMENT}" arg2="local" trim="true"/>
        </condition>
    </target>

    <target name="if.chunks.exist">
        <condition property="files.exist">
            <resourcecount when="greater" count="0">
                <fileset id="page_files" dir="${chunk.dir}" includes="**/*.xml" />
            </resourcecount>
        </condition>
    </target>

</project>
